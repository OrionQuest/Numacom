
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>2.4. Matrix Norms and Condition Numbers &#8212; CS 323 1.0 documentation</title>
    <link rel="stylesheet" href="_static/classic.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '1.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="3. Getting Started with Python" href="python.html" />
    <link rel="prev" title="2.3. Norms" href="norms.html" /> 
  </head>
  <body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="python.html" title="3. Getting Started with Python"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="norms.html" title="2.3. Norms"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">CS 323 1.0 documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="algebra.html" accesskey="U">2. Vector and Matrix Algebra</a> &#187;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="matrix-norms-and-condition-numbers">
<h1>2.4. Matrix Norms and Condition Numbers<a class="headerlink" href="#matrix-norms-and-condition-numbers" title="Permalink to this headline">¶</a></h1>
<p>Similar to vectors, norms can also be defined for (square) matrices. These norms
allow us to measure the <em>nicety</em> of a linear system in terms of admitting stable
numerical algorithms. It turns out these norms allow us to precisly quantify the
convergence behavior of many iterative schemes, as we will see in later
sections.</p>
<div class="section" id="matrix-norms">
<h2>2.4.1. Matrix Norms<a class="headerlink" href="#matrix-norms" title="Permalink to this headline">¶</a></h2>
<div class="topic">
<p class="topic-title first">Definition</p>
<p>A matrix norm is a function <span class="math">\(\lVert\cdot\rVert : \mathbb R^{n\times n}\rightarrow \mathbb R\)</span> that satisfies:</p>
<ol class="arabic simple">
<li><span class="math">\(\lVert M\rVert\geq 0\)</span> for all <span class="math">\(M\in\mathbb R^{n\times n}\)</span>, <span class="math">\(\lVert M\rVert = 0\)</span>
if and only if <span class="math">\(M=O\)</span>.</li>
<li><span class="math">\(\lVert \alpha M\rVert = \vert\alpha\vert\cdot\lVert M\rVert\)</span></li>
<li><span class="math">\(\lVert M+N\rVert\leq \lVert M\rVert + \lVert N\rVert\)</span></li>
<li><span class="math">\(\lVert M\cdot N\rVert \leq \lVert M\rVert\cdot\lVert N\rVert\)</span></li>
</ol>
</div>
<p>Property <span class="math">\((4)\)</span> above has slightly different flavor than vector
norms. Although more types of matrix norms exist, one common category is that of
matrix norms <em>induced by</em> vector norms.</p>
<div class="topic">
<p class="topic-title first">Definition</p>
<p>If <span class="math">\(\lVert\cdot\rVert_\star\)</span> is a valid vector norm, its
<em>induced</em> matrix norm is defined as:</p>
<div class="math">
\[\lVert M\rVert_\star = \max_{x\in\mathbb R^n,x\neq 0} \frac{\lVert Mx\rVert_\star}{\lVert x\rVert_\star}\]</div>
<p>or equivalently,</p>
<div class="math">
\[\lVert M\rVert_\star = \max_{x\in\mathbb R^n,\lVert x\rVert=1} \lVert Mx\rVert_\star\]</div>
</div>
<p>Note again, that <em>not all</em> valid matrix norms are induced by vector norms. One
notable example is the very commonly used <em>Frobenius norm</em>:</p>
<div class="math">
\[\lVert M\rVert_F = \sqrt{\sum_{i,j=1}^n M_{ij}^2}\]</div>
<p>We can easily show that induced norms satify properties <span class="math">\((1)\)</span> through
<span class="math">\((4)\)</span>. Properties <span class="math">\((1)-(3)\)</span> are rather trivial, for example,</p>
<div class="math">
\[\begin{split}\lVert M+N\rVert &amp;=&amp; \max_{x\neq 0} \frac{\lVert (M+N)x\rVert}{\lVert x\rVert} \leq \max_{x\neq 0} \frac{\lVert Mx\rVert + \lVert Nx\rVert}{\lVert x\rVert} \\
                 &amp;=&amp; \max_{x\neq 0} \frac{\lVert Mx\rVert}{\lVert x\rVert} + \max_{x\neq 0} \frac{\lVert Nx\rVert}{\lVert x\rVert} = \lVert M\rVert + \lVert N\rVert\end{split}\]</div>
<p>Property <span class="math">\((4)\)</span> is slightly trickier to show. First, a lemma:</p>
<div class="topic">
<p class="topic-title first">Lemma</p>
<p>If <span class="math">\(\lVert\cdot\rVert\)</span> is a matrix norm induced by a vector
norm <span class="math">\(\lVert\cdot\rVert\)</span>, then</p>
<div class="math" id="equation-vector-norm-inequality">
<span class="eqno">(1)<a class="headerlink" href="#equation-vector-norm-inequality" title="Permalink to this equation">¶</a></span>\[\lVert Ax\rVert \leq \lVert A\rVert\cdot \lVert x\rVert\]</div>
<p><em>Proof:</em> Since <span class="math">\(\lVert A\rVert = \max_{x\neq 0}\lVert Ax\rVert/\lVert x\rVert\)</span>, we have that for an arbitrary <span class="math">\(y\in\mathbb R^n (y\neq 0)\)</span></p>
<div class="math">
\[\lVert A\rVert = \max_{x\neq 0}\frac{\lVert Ax\rVert}{\lVert x\rVert}\geq \frac{\lVert Ay\rVert}{\lVert y\rVert} \Rightarrow \lVert Ay\rVert \leq \lVert A\rVert\cdot\lVert y\rVert\]</div>
<p>This holds for <span class="math">\(y\neq 0\)</span>, but we can see that it is also true for <span class="math">\(y=0\)</span>.</p>
</div>
<p>Now property <span class="math">\((4)\)</span> can be easily proved using the above lemma:</p>
<div class="math">
\[\begin{split}\lVert MN\rVert &amp;=&amp; \max_{\lVert x\rVert=1} \lVert MNx\rVert \leq \max_{\lVert x\rVert=1} \lVert M\rVert\cdot \lVert Nx\rVert \\
                &amp;=&amp; \lVert M\rVert\cdot \max_{\lVert x\rVert=1} \lVert Nx\rVert = \lVert M\rVert\cdot\lVert N\rVert \\
\Rightarrow \lVert MN\rVert &amp;\leq&amp; \lVert M\rVert\cdot\lVert N\rVert\end{split}\]</div>
<p>Note that when writing an expression such as <a class="reference internal" href="#equation-vector-norm-inequality">(1)</a>, the
matrix norm <span class="math">\(\lVert A\rVert\)</span> is understood to be the inferred norm from the
vector norm used in <span class="math">\(\lVert Ax\rVert\)</span> and <span class="math">\(\lVert x\rVert\)</span>. Thus,</p>
<div class="math">
\[\lVert Ax\rVert_1 \leq \lVert A\rVert_1\cdot \lVert x\rVert_1\]</div>
<p>and</p>
<div class="math">
\[\lVert Ax\rVert_\infty \leq \lVert A\rVert_\infty\cdot \lVert x\rVert_\infty\]</div>
<p>are both valid, but we <em>cannot</em> mix and match, for example:</p>
<div class="math">
\[\lVert Ax\rVert_\infty \leq \lVert A\rVert_2\cdot \lVert x\rVert_1\]</div>
<p>Although the definition of an induced norm allowed us to prove certain
properties, it does not necessarily provide a convenient formula for evaluating
the matrix norm. Fortunately, such formulas do exist for the <span class="math">\(L_1\)</span> and
<span class="math">\(L_\infty\)</span> induced matrix norms. Given here (without proof):</p>
<div class="math">
\[\begin{split}\lVert A\rVert_1        &amp;=&amp; \max_j \sum_{i=1}^n \vert A_{ij}\vert \enspace\enspace\enspace\mbox{(maximum absolute column sum)} \\
\lVert A\rVert_\infty   &amp;=&amp; \max_i \sum_{i=1}^n \vert A_{ij}\vert \enspace\enspace\enspace\mbox{(maximum absolute row sum)}\end{split}\]</div>
<p>The formula for the <span class="math">\(L_2\)</span> induced matrix norm is more complicated. We will see it when we study eigenvalues.</p>
</div>
<div class="section" id="condition-numbers">
<h2>2.4.2. Condition Numbers<a class="headerlink" href="#condition-numbers" title="Permalink to this headline">¶</a></h2>
<p>When solving a linear system <span class="math">\(Ax=b\)</span>, computer algorithms are only
providing an approximation <span class="math">\(x_\textsf{approx}\)</span> to the exact solution
<span class="math">\(x_\textsf{exact}\)</span>. This is due to factors such as finite precision,
round-off errors, or even imperfect solution algorithms. In either case, we have
an <em>error</em> (in fact, an error vector) defined as:</p>
<div class="math">
\[e = x_\textsf{approx} - x_\textsf{exact}\]</div>
<p>Naturally, we would like to have an understanding of the <em>magnitude</em> of this
error (for example, some appropriate norm <span class="math">\(\lVert e\rVert\)</span>). However, the
error cannot be directly measured because the exact solution <span class="math">\(x_\textsf{exact}\)</span> is unknown.
One remedy is offered via the <em>residual vector</em> defined as:</p>
<div class="math">
\[r = b-Ax_\textsf{approx}\]</div>
<p>The vector <span class="math">\(r\)</span> is something we <em>can</em> compute practically since it involves
only the known quantities <span class="math">\(b, A, x_\textsf{approx}\)</span>. Moreover, we have:</p>
<div class="math" id="equation-error-vs-residual">
<span class="eqno">(2)<a class="headerlink" href="#equation-error-vs-residual" title="Permalink to this equation">¶</a></span>\[\begin{split}r               \enspace &amp;=&amp; \enspace b-Ax_\textsf{approx} \nonumber \\
                \enspace &amp;=&amp; \enspace Ax_\textsf{exact} - Ax_\textsf{approx} \\
                \enspace &amp;=&amp; \enspace -A(x_\textsf{approx} - x_\textsf{exact}) \\
                \enspace &amp;=&amp; \enspace -Ae \\
\Rightarrow r   \enspace &amp;=&amp; \enspace -Ae \\
\Rightarrow e   \enspace &amp;=&amp; \enspace -A^{-1}r\end{split}\]</div>
<p>Equation <a class="reference internal" href="#equation-error-vs-residual">(2)</a> links the error with the residual. This allows
us to write:</p>
<div class="math">
\[\lVert e\rVert = \lVert A^{-1}r\rVert \leq \lVert A^{-1}\rVert\cdot\lVert r\rVert\]</div>
<p>This equation provides a <em>bound</em> for the error, as a function of <span class="math">\(\lVert A^{-1}\rVert\)</span>
and the norm of the computable vector <span class="math">\(r\)</span>. Note that:</p>
<ul class="simple">
<li>We can obtain this estimate <em>without</em> knowing the exact solution, but</li>
<li>We need <span class="math">\(\lVert A^{-1}\rVert\)</span> and generally, computing <span class="math">\(\lVert A^{-1}\rVert\)</span>
is just as difficult (if not more) than finding <span class="math">\(x_\textsf{exact}\)</span>. However, there
<em>are</em> some special cases where an estimate of <span class="math">\(\lVert A^{-1}\rVert\)</span> can be obtained.</li>
</ul>
</div>
<div class="section" id="a-different-source-of-error">
<h2>2.4.3. A Different Source of Error<a class="headerlink" href="#a-different-source-of-error" title="Permalink to this headline">¶</a></h2>
<p>Sometimes, the right hand side <span class="math">\(b\)</span> of the system of equations <span class="math">\(Ax=b\)</span>
has errors that make it deviate from its intended value. For example, if each
component of <span class="math">\(b\)</span> was defined as <span class="math">\(b_i=f(x_i)\)</span>, where <span class="math">\(f\)</span> is an
unknown function, then an error in a
measuring device that was supposed to sample <span class="math">\(f(x)\)</span> could lead to
erroneous readings <span class="math">\(b_i^\star (\neq b_i)\)</span>. Thus,
measuring inaccuracies can lead to the right hand side vector <span class="math">\(b\)</span> being
misrepresented as <span class="math">\(b^\star\)</span>. In this case, instead of the
intended solution <span class="math">\(x=A^{-1}b\)</span>, we compute the solution to a
different system <span class="math">\(x^\star=A^{-1}b^\star\)</span>. How important is the error
<span class="math">\(e=x^\star-x\)</span> that is caused by this misrepresentation of <span class="math">\(b\)</span>?
Let <span class="math">\(\delta b=b^\star-b, \delta x=x^\star-x,Ax=b,Ax^\star=b^\star\)</span>. Then,
we have:</p>
<div class="math">
\[\begin{split}A(x^\star-x)            \enspace &amp;=&amp; \enspace b^\star-b \\
A\delta x               \enspace &amp;=&amp; \enspace \delta b \\
\Rightarrow \delta x    \enspace &amp;=&amp; \enspace A^{-1}\delta b\end{split}\]</div>
<p>Taking norms,</p>
<div class="math" id="equation-error-norm">
<span class="eqno">(3)<a class="headerlink" href="#equation-error-norm" title="Permalink to this equation">¶</a></span>\[\lVert \delta x\rVert = \lVert A^{-1}\delta b\rVert \leq \lVert A^{-1}\rVert\cdot\lVert \delta b\rVert\]</div>
<p>Thus, the error in the computed solution <span class="math">\(\delta x\)</span> is proportional to the
error in <span class="math">\(b\)</span>. An even more relevant question is: how does the <em>relative</em>
error <span class="math">\(\lVert \delta x\rVert/\lVert x\rVert = \lVert
x^\star-x\rVert/\lVert x\rVert\)</span> compare to the relative error in <span class="math">\(b\)</span>
(<span class="math">\(\lVert\delta b\rVert/\lVert b\rVert\)</span>)? This may be more useful to know,
since <span class="math">\(\lVert\delta b\rVert\)</span> may be impossible to compute (if we don’t
know the real <span class="math">\(b\)</span>). For this, we write:</p>
<div class="math" id="equation-error-reciprocal">
<span class="eqno">(4)<a class="headerlink" href="#equation-error-reciprocal" title="Permalink to this equation">¶</a></span>\[\begin{split}Ax = b  &amp;\Rightarrow&amp; \lVert b\rVert = \lVert Ax\rVert \leq \lVert A\rVert\cdot\lVert x\rVert \\
        &amp;\Rightarrow&amp; \frac{1}{\lVert x\rVert} \leq \lVert A\rVert\cdot\frac{1}{\lVert b\rVert}\end{split}\]</div>
<p>Multiplying equation <a class="reference internal" href="#equation-error-norm">(3)</a> and <a class="reference internal" href="#equation-error-reciprocal">(4)</a> gives</p>
<div class="math">
\[\frac{\lVert\delta x\rVert}{\lVert x\rVert} \leq \underbrace{\lVert A\rVert\cdot\lVert A^{-1}\rVert}_{\kappa (A)}\cdot\frac{\lVert \delta b\rVert}{\lVert b\rVert}\]</div>
<p>Thus, the relative error in <span class="math">\(x\)</span> is bounded by a multiple of the relative
error in <span class="math">\(b\)</span>. This multiplicative constant <span class="math">\(\kappa (A)=\lVert A\rVert\cdot\lVert A^{-1}\rVert\)</span>
is called the <em>condition number</em> of <span class="math">\(A\)</span>, and is an important measure of
the sensitivity of a linear system <span class="math">\(Ax=b\)</span> to being solved on a computer
in the presence of inaccurate values.</p>
</div>
<div class="section" id="why-is-all-this-relevant">
<h2>2.4.4. Why is all this relevant?<a class="headerlink" href="#why-is-all-this-relevant" title="Permalink to this headline">¶</a></h2>
<p>Simply put, <em>any</em> <span class="math">\(b\)</span> will have <em>some</em> small relative error due to the
fact that it is represented on a computer only up to machine precision. The relative
error will be at least as much as the machine epsilon due to round-off.</p>
<div class="math">
\[\frac{\lVert\delta b\rVert_\infty}{\lVert b\rVert_\infty} \geq\varepsilon\approx 10^{-7} \enspace\enspace\enspace\enspace\mbox{(in single precision)}\]</div>
<p>But how bad can the condition number get? <em>Very bad</em> at times. For example,
<a class="reference external" href="https://en.wikipedia.org/wiki/Hilbert_matrix">Hilbert matrices</a>
<span class="math">\(H_n\in\mathbb R^{n\times n}\)</span> are defined as:</p>
<div class="math">
\[(H_n)_{ij} = \frac{1}{i+j-1}\]</div>
<p>Considering a specific instance for <span class="math">\(n=5\)</span>,</p>
<div class="math">
\[\begin{split}H_5=\left[\begin{array}{ccccc}
1 &amp; 1/2 &amp; 1/3 &amp; 1/4 &amp; 1/5 \\
1/2 &amp; 1/3 &amp; 1/4 &amp; 1/5 &amp; 1/6 \\
1/3 &amp; 1/4 &amp; 1/5 &amp; 1/6 &amp; 1/7 \\
1/4 &amp; 1/5 &amp; 1/6 &amp; 1/7 &amp; 1/8 \\
1/5 &amp; 1/6 &amp; 1/7 &amp; 1/8 &amp; 1/9
\end{array}\right], \enspace\enspace\enspace\enspace\enspace \kappa_\infty(H_5) = \lVert H_5\rVert_\infty\cdot\lVert H_5^{-1}\rVert_\infty\approx 10^{6}\end{split}\]</div>
<p>Thus, any attempt at solving <span class="math">\(H_5 x = b\)</span> would be subject to a relative
error of up to <span class="math">\(10\%\)</span> <em>just due to</em> round-off errors in <span class="math">\(b\)</span>! Another
case is that of near-singular matrices, for example:</p>
<div class="math">
\[\begin{split}A=\left[\begin{array}{cc}
1 &amp; 2 \\
3 &amp; 6+\varepsilon
\end{array}\right]\end{split}\]</div>
<p>As <span class="math">\(\varepsilon\rightarrow 0\)</span>, the matrix <span class="math">\(A\)</span> becomes <em>singular</em>
(non-invertible). In this case, <span class="math">\(\kappa (A)\rightarrow\infty\)</span>.</p>
<p>So far, we have considered upper bounds on the condition number. One may also
ask what is the best case scenario for <span class="math">\(\kappa (A)\)</span>? Before we answer this
question, a lemma:</p>
<div class="topic">
<p class="topic-title first">Lemma</p>
<p>For any vector-induced matrix norm, <span class="math">\(\lVert I\rVert = 1\)</span>.</p>
<p><em>Proof:</em>  From the definition,</p>
<div class="math">
\[\lVert I\rVert = \max_{x\neq 0}\frac{\lVert Ix\rVert}{\lVert x\rVert} = \max_{x\neq 0} \frac{\lVert x\rVert}{\lVert x\rVert} = 1\]</div>
</div>
<p>Using property (4) of matrix norms, we have:</p>
<div class="math">
\[I = A\cdot A^{-1} \Rightarrow 1 = \lVert I\rVert = \lVert A\cdot A^{-1}\rVert \leq \lVert A\rVert\cdot\lVert A^{-1}\rVert\]</div>
<p>Thus, <span class="math">\(\kappa (A)\geq 1\)</span>. The “best” conditioned matrices are of the form
<span class="math">\(A=c\cdot I\)</span>, where <span class="math">\(c\in\mathbb R\)</span> is a non-zero constant, and have
<span class="math">\(\kappa (A)=1\)</span>. The <code class="docutils literal"><span class="pre">linalg</span></code> package of <a class="reference external" href="http://www.numpy.org/">NumPy</a>
has an in-built function <code class="docutils literal"><span class="pre">cond</span></code> for computing the condition number of any square matrix, as
shown below. The second parameter specifies the particular norm to use
for evaluating the condition number.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matrix</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">],[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">matrix([[ 1,  0, -1],</span>
<span class="go">        [ 0,  1,  0],</span>
<span class="go">        [ 1,  0,  1]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cond</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="go">2.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cond</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="go">1.4142135623730951</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cond</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">)</span>
<span class="go">2.0</span>
</pre></div>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">2.4. Matrix Norms and Condition Numbers</a><ul>
<li><a class="reference internal" href="#matrix-norms">2.4.1. Matrix Norms</a></li>
<li><a class="reference internal" href="#condition-numbers">2.4.2. Condition Numbers</a></li>
<li><a class="reference internal" href="#a-different-source-of-error">2.4.3. A Different Source of Error</a></li>
<li><a class="reference internal" href="#why-is-all-this-relevant">2.4.4. Why is all this relevant?</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="norms.html"
                        title="previous chapter">2.3. Norms</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="python.html"
                        title="next chapter">3. Getting Started with Python</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/condition.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="python.html" title="3. Getting Started with Python"
             >next</a> |</li>
        <li class="right" >
          <a href="norms.html" title="2.3. Norms"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">CS 323 1.0 documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="algebra.html" >2. Vector and Matrix Algebra</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2017, Mridul Aanjaneya.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.6.3.
    </div>
  </body>
</html>