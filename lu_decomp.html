<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>4.3. LU Decomposition &mdash; CS 323 1.0 documentation</title>
    
    <link rel="stylesheet" href="_static/classic.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '1.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="top" title="CS 323 1.0 documentation" href="index.html" />
    <link rel="up" title="4. Linear Systems of Equations" href="linear.html" />
    <link rel="prev" title="4.2. Lower Triangular Systems" href="lower.html" /> 
  </head>
  <body role="document">
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="lower.html" title="4.2. Lower Triangular Systems"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">CS 323 1.0 documentation</a> &raquo;</li>
          <li class="nav-item nav-item-1"><a href="linear.html" accesskey="U">4. Linear Systems of Equations</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="lu-decomposition">
<h1>4.3. LU Decomposition<a class="headerlink" href="#lu-decomposition" title="Permalink to this headline">¶</a></h1>
<p>The forward and backward substitution algorithms can be used to solve a
<em>non-triangular</em> system by virtue of the following factorization property:</p>
<div class="topic">
<p class="topic-title first">Theorem 1</p>
<p>If <span class="math">\(A\)</span> is an <span class="math">\(n\times n\)</span> matrix, it can be (generally) written as a product</p>
<div class="math">
\[A = LU\]</div>
<p>where <span class="math">\(L\)</span> is a lower triangular matrix and <span class="math">\(U\)</span> is an upper
triangular matrix. Furthermore, it is possible to construct <span class="math">\(L\)</span> such
that all diagonal elements <span class="math">\(l_{ii}=1\)</span>.</p>
</div>
<p>The code below outlines the <em>Gaussian Elimination</em> algorithm to compute the <span class="math">\(LU\)</span> factorization of an
<span class="math">\(n\times n\)</span> matrix.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="c1"># LU decomposition of square systems</span>
<span class="k">def</span> <span class="nf">Gaussian_Elimination</span><span class="p">(</span><span class="n">A</span><span class="p">):</span>
    <span class="n">m</span><span class="o">=</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">n</span><span class="o">=</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">if</span><span class="p">(</span><span class="n">m</span><span class="o">!=</span><span class="n">n</span><span class="p">):</span>
        <span class="k">print</span> <span class="s1">&#39;Matrix is not square!&#39;</span>
        <span class="k">return</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">A</span><span class="p">[</span><span class="n">k</span><span class="p">,</span><span class="n">k</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="n">n</span><span class="p">):</span>
            <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">k</span><span class="p">]</span><span class="o">=</span><span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">k</span><span class="p">]</span><span class="o">/</span><span class="n">A</span><span class="p">[</span><span class="n">k</span><span class="p">,</span><span class="n">k</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="n">n</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="n">n</span><span class="p">):</span>
                <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="o">-=</span><span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">k</span><span class="p">]</span><span class="o">*</span><span class="n">A</span><span class="p">[</span><span class="n">k</span><span class="p">,</span><span class="n">j</span><span class="p">]</span>
</pre></div>
</div>
<p>Note that the algorithm above executes <em>in-place</em>, i.e., the matrix <span class="math">\(A\)</span> is
<em>replaced by</em> its <span class="math">\(LU\)</span> factorization, in compact form. More specifically,
this algorithm produces a factorization <span class="math">\(A=LU\)</span>, where:</p>
<div class="math">
\[\begin{split}L=\left[
\begin{array}{cccccc}
1 &amp; &amp; &amp; &amp; &amp; \\
l_{21} &amp; 1 &amp; &amp; &amp; O &amp; \\
l_{31} &amp; l_{32} &amp; 1 &amp; &amp; &amp; \\
l_{41} &amp; l_{42} &amp; l_{43} &amp; 1 &amp; &amp; \\
\vdots &amp; \vdots &amp; \vdots &amp; &amp; \ddots &amp; \\
l_{n1} &amp; n_{n2} &amp; l_{n3} &amp; \ldots &amp; l_{n,n-1} &amp; 1
\end{array}
\right],\enspace\enspace U=\left[
\begin{array}{ccccc}
u_{11} &amp; u_{12} &amp; u_{13} &amp; \ldots &amp; u_{1n} \\
&amp; u_{22} &amp; u_{23} &amp; \ldots &amp; u_{2n} \\
&amp; &amp; u_{33} &amp; \ldots &amp; u_{3n} \\
&amp; O &amp; &amp; \ddots &amp; u_{n-1,n} \\
&amp; &amp; &amp; &amp; u_{nn}
\end{array}
\right]\end{split}\]</div>
<p>After the in-place factorization algorithm completes, <span class="math">\(A\)</span> is replaced by
the following <em>compacted</em> encoding of <span class="math">\(L\)</span> and <span class="math">\(U\)</span> together:</p>
<div class="math">
\[\begin{split}A=\left[
\begin{array}{ccccc}
u_{11} &amp; u_{12} &amp; u_{13} &amp; \ldots &amp; u_{1n} \\
l_{21} &amp; u_{22} &amp; u_{23} &amp; \ldots &amp; u_{2n} \\
l_{31} &amp; l_{32} &amp; u_{33} &amp; \ldots &amp; u_{3n} \\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
l_{n1} &amp; l_{n2} &amp; \ldots &amp; l_{n-1,n} &amp; u_{nn}
\end{array}
\right]\end{split}\]</div>
<div class="topic">
<p class="topic-title first">Example</p>
<p>Consider the matrix shown below.</p>
<div class="math">
\[\begin{split}\left[\begin{array}{ccc}
2 &amp; 4 &amp; -2 \\
4 &amp; 9 &amp; -3 \\
-2 &amp; -3 &amp; 7
\end{array}\right]\end{split}\]</div>
<p>Let us append the following code to the
Gaussian Elimination algorithm outlined above to compute the corresponding <span class="math">\(LU\)</span> factorization:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">A</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">matrix</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="o">-</span><span class="mi">2</span><span class="p">],[</span><span class="mi">4</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="o">-</span><span class="mi">3</span><span class="p">],[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">7</span><span class="p">]])</span>
    <span class="n">Gaussian_Elimination</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
    <span class="k">print</span> <span class="n">A</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
<p>Upon execution, it produces the following result:</p>
<div class="highlight-python"><div class="highlight"><pre>[[ 2  4 -2]
 [ 2  1  1]
 [-1  1  4]]
</pre></div>
</div>
<p>As stated above, the factorization is <em>in-place</em>, and so the result should be
interpreted as:</p>
<div class="math">
\[\begin{split}L = \left[\begin{array}{ccc}
1 &amp; 0 &amp; 0 \\
2 &amp; 1 &amp; 0 \\
-1 &amp; 1 &amp; 1
\end{array}\right],\enspace\enspace\enspace
U=\left[\begin{array}{ccc}
2 &amp; 4 &amp; -2 \\
0 &amp; 1 &amp; 1 \\
0 &amp; 0 &amp; 4
\end{array}\right]\end{split}\]</div>
</div>
<div class="section" id="elimination-matrices">
<h2>4.3.1. Elimination Matrices<a class="headerlink" href="#elimination-matrices" title="Permalink to this headline">¶</a></h2>
<p>Here is a slightly different algorithm for computing the <span class="math">\(LU\)</span>
factorization of an <span class="math">\(n\times n\)</span> matrix by using <em>elimination matrices</em>.
Define the <span class="math">\(n\times 1\)</span> basis vector <span class="math">\(e_k\)</span> as</p>
<div class="math">
\[\begin{split}e_k=\left(
\begin{array}{c}
0 \\
\vdots \\
0 \\
1 \\
0 \\
\vdots \\
0
\end{array}
\right)\end{split}\]</div>
<p>where the <span class="math">\(1\)</span> is in the <span class="math">\(k^{th}\)</span> row and the length of
<span class="math">\(e_k\)</span> is <span class="math">\(n\)</span>. In order to perform Gaussian Elimination on the
<span class="math">\(k^{th}\)</span> column <span class="math">\(a_k\)</span> of <span class="math">\(A\)</span>, we define the
<span class="math">\(n\times n\)</span> elimination matrix <span class="math">\(M_k = I-m_ke_k^T\)</span> where</p>
<div class="math">
\[\begin{split}m_k=\frac{1}{a_{kk}}\cdot\left(
\begin{array}{c}
0 \\
\vdots \\
0 \\
a_{k+1,k} \\
\vdots \\
a_{n,k}
\end{array}
\right)\end{split}\]</div>
<p><span class="math">\(M_k\)</span> adds multiples of row <span class="math">\(k\)</span> to rows with index greater than <span class="math">\(k\)</span> in order to create zeroes. As an
example, for <span class="math">\(a_k=(2,4,-2)^T\)</span></p>
<div class="math">
\[\begin{split}M_1a_k=\left[
\begin{array}{ccc}
1 &amp; 0 &amp; 0 \\
-2 &amp; 1 &amp; 0 \\
1 &amp; 0 &amp; 1
\end{array}
\right]
\left[
\begin{array}{c}
2 \\
4 \\
-2
\end{array}
\right]=\left[
\begin{array}{c}
2 \\
0 \\
0
\end{array}
\right]\end{split}\]</div>
<p>Similarly,</p>
<div class="math">
\[\begin{split}M_2a_k=\left[
\begin{array}{ccc}
1 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 \\
0 &amp; 1/2 &amp; 1
\end{array}
\right]
\left[
\begin{array}{c}
2 \\
4 \\
-2
\end{array}
\right]=\left[
\begin{array}{c}
2 \\
4 \\
0
\end{array}
\right]\end{split}\]</div>
<p>The inverse of an elimination matrix is defined as
<span class="math">\(L_k=M_k^{-1}=I+m_ke_k^T\)</span>. For example,</p>
<div class="math">
\[\begin{split}L_1=M_1^{-1}=\left[
\begin{array}{ccc}
1 &amp; 0 &amp; 0 \\
2 &amp; 1 &amp; 0 \\
-1 &amp; 0 &amp; 1
\end{array}
\right],\enspace\mbox{and}\enspace L_2=M_2^{-1}=\left[
\begin{array}{ccc}
1 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 \\
0 &amp; -1/2 &amp; 1
\end{array}
\right]\end{split}\]</div>
<p>The algorithm now proceeds as follows. Consider the example:</p>
<div class="math">
\[\begin{split}\left[
\begin{array}{ccc}
2 &amp; 4 &amp; -2 \\
4 &amp; 9 &amp; -3 \\
-2 &amp; -3 &amp; 7
\end{array}
\right]
\left[
\begin{array}{c}
x_1 \\
x_2 \\
x_3
\end{array}
\right]=\left[
\begin{array}{c}
2 \\
8 \\
10
\end{array}
\right]\end{split}\]</div>
<p>First, we eliminate the lower triangular portion of <span class="math">\(A\)</span> one column at a time
using <span class="math">\(M_k\)</span> to get <span class="math">\(U=M_{n-1}\ldots M_1A\)</span>. Note that we also carry out the
operations on <span class="math">\(b\)</span> to get a new system of equations <span class="math">\(M_2M_1Ax=M_2M_1b\)</span> or
<span class="math">\(Ux=M_2M_1b\)</span> which can be solved for via back substitution.</p>
<div class="math">
\[\begin{split}M_1A=\left[
\begin{array}{ccc}
1 &amp; 0 &amp; 0 \\
-2 &amp; 1 &amp; 0 \\
1 &amp; 0 &amp; 1
\end{array}
\right]\left[
\begin{array}{ccc}
2 &amp; 4 &amp; -2 \\
4 &amp; 9 &amp; -3 \\
-2 &amp; -3 &amp; 7
\end{array}
\right]=\left[
\begin{array}{ccc}
2 &amp; 4 &amp; -2 \\
0 &amp; 1 &amp; 1 \\
0 &amp; 1 &amp; 5
\end{array}
\right]\end{split}\]</div>
<div class="math">
\[\begin{split}M_1b=\left[
\begin{array}{ccc}
1 &amp; 0 &amp; 0 \\
-2 &amp; 1 &amp; 0 \\
1 &amp; 0 &amp; 1
\end{array}
\right]\left[
\begin{array}{c}
2 \\
8 \\
10
\end{array}
\right]=\left[
\begin{array}{c}
2 \\
4 \\
12
\end{array}
\right]\end{split}\]</div>
<div class="math">
\[\begin{split}M_2M_1A=\left[
\begin{array}{ccc}
1 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 \\
0 &amp; -1 &amp; 1
\end{array}
\right]\left[
\begin{array}{ccc}
2 &amp; 4 &amp; -2 \\
0 &amp; 1 &amp; 1 \\
0 &amp; 1 &amp; 5
\end{array}
\right]=\left[
\begin{array}{ccc}
2 &amp; 4 &amp; -2 \\
0 &amp; 1 &amp; 1 \\
0 &amp; 0 &amp; 4
\end{array}
\right]\end{split}\]</div>
<div class="math">
\[\begin{split}M_2M_1b=\left[
\begin{array}{ccc}
1 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 \\
0 &amp; -1 &amp; 1
\end{array}
\right]\left[
\begin{array}{c}
2 \\
4 \\
12
\end{array}
\right]=\left[
\begin{array}{c}
2 \\
4 \\
8
\end{array}
\right]\end{split}\]</div>
<p>Finally, solve the following system via back substitution.</p>
<div class="math">
\[\begin{split}\left[
\begin{array}{ccc}
2 &amp; 4 &amp; -2 \\
0 &amp; 1 &amp; 1 \\
0 &amp; 0 &amp; 4
\end{array}
\right]\left[
\begin{array}{c}
x \\
y \\
z
\end{array}
\right]=\left[
\begin{array}{c}
2 \\
4 \\
8
\end{array}
\right]\end{split}\]</div>
<p>Note that we can write <span class="math">\(LU=(L_1\ldots L_{n-1})(M_{n-1}\ldots M_1A)=A\)</span>
using the fact that the <span class="math">\(L\)</span> matrices are inverses of the <span class="math">\(M\)</span> matrices,
where <span class="math">\(L=L_1\ldots L_{n-1}\)</span> can be formed trivially from the <span class="math">\(M_k\)</span> to obtain:</p>
<div class="math">
\[\begin{split}L=L_1L_2=\left[
\begin{array}{ccc}
1 &amp; 0 &amp; 0 \\
2 &amp; 1 &amp; 0 \\
-1 &amp; 0 &amp; 1
\end{array}
\right]\left[
\begin{array}{ccc}
1 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 \\
0 &amp; 1 &amp; 1
\end{array}
\right]=\left[
\begin{array}{ccc}
1 &amp; 0 &amp; 0 \\
2 &amp; 1 &amp; 0 \\
-1 &amp; 1 &amp; 1
\end{array}
\right]\end{split}\]</div>
<p>And thus, although we never needed it to solve the equations, the <span class="math">\(LU\)</span>
factorization of <span class="math">\(A\)</span> is</p>
<div class="math">
\[\begin{split}A=\left[
\begin{array}{ccc}
2 &amp; 4 &amp; -2 \\
4 &amp; 9 &amp; -3 \\
-2 &amp; -3 &amp; 7
\end{array}
\right]=\left[
\begin{array}{ccc}
1 &amp; 0 &amp; 0 \\
2 &amp; 1 &amp; 0 \\
-1 &amp; 1 &amp; 1
\end{array}
\right]\left[
\begin{array}{ccc}
2 &amp; 4 &amp; -2 \\
0 &amp; 1 &amp; 1 \\
0 &amp; 0 &amp; 4
\end{array}
\right]=LU\end{split}\]</div>
</div>
<div class="section" id="existence-and-uniqueness">
<h2>4.3.2. Existence and Uniqueness<a class="headerlink" href="#existence-and-uniqueness" title="Permalink to this headline">¶</a></h2>
<p>When computing the <span class="math">\(LU\)</span> factorization, the algorithm will <em>halt</em> if the
diagonal element <span class="math">\(a_{kk}=0\)</span>. This can be avoided by swapping rows of
<span class="math">\(A\)</span> prior to computing the <span class="math">\(LU\)</span> factorization. This is done to
always select the largest <span class="math">\(a_{kk}\)</span> from the equations that follow. As an
example, consider the matrix <span class="math">\(A\)</span> and the action of the permutation matrix
<span class="math">\(P\)</span> on it.</p>
<div class="math">
\[\begin{split}A=\left[
\begin{array}{cccc}
1 &amp; 2 &amp; 5 &amp; -1 \\
0 &amp; 0 &amp; 3 &amp; 1 \\
0 &amp; 4 &amp; 1 &amp; -2 \\
0 &amp; -6 &amp; 0 &amp; 3
\end{array}
\right],\enspace\enspace P=\left[
\begin{array}{cccc}
1 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 1 \\
0 &amp; 0 &amp; 1 &amp; 0 \\
0 &amp; 1 &amp; 0 &amp; 0
\end{array}
\right],\enspace\enspace PA=\left[
\begin{array}{cccc}
1 &amp; 2 &amp; 5 &amp; -1 \\
0 &amp; -6 &amp; 0 &amp; 3 \\
0 &amp; 4 &amp; 1 &amp; -2 \\
0 &amp; 0 &amp; 3 &amp; 1
\end{array}
\right]\end{split}\]</div>
<p>This is <em>pivoting</em>: the pivot <span class="math">\(a_{kk}\)</span> is selected to be non-zero. In this
process, we can guarantee existence and uniqueness of the <span class="math">\(LU\)</span> factorization.</p>
<div class="topic">
<p class="topic-title first">Theorem 2</p>
<p>If <span class="math">\(P\)</span> is a permutation matrix such that all pivots in the Gaussian
Elimination of <span class="math">\(PA\)</span> are non-zero, then the <span class="math">\(LU\)</span> factorization
exists and is unique.</p>
<div class="math">
\[PA = LU\]</div>
</div>
<p>So far, we have seen two ways of solving the system <span class="math">\(Ax=b\)</span>:</p>
<ul>
<li><p class="first">Without pivoting:</p>
<blockquote>
<div><div class="math">
\[A = L\underbrace{Ux}_{=y} = b\]</div>
<ol class="arabic simple">
<li>Solve <span class="math">\(Ly = b\)</span> through forward substitution.</li>
<li>Solve <span class="math">\(Ux = y\)</span> through backward substitution to obtain the
solution <span class="math">\(x\)</span>.</li>
</ol>
<p>Note that if we have multiple systems <span class="math">\(Ax_i = b_i\)</span>, we only need to
incur the cost of computing an <span class="math">\(LU\)</span> decomposition of <span class="math">\(A\)</span> once.</p>
</div></blockquote>
</li>
<li><p class="first">With pivoting:</p>
<blockquote>
<div><div class="math">
\[Ax = b \Longleftrightarrow PAx = Pb\]</div>
<ol class="arabic simple">
<li>Solve <span class="math">\(Ly = Pb\)</span> using forward substitution.</li>
<li>Solve <span class="math">\(Ux = y\)</span> using backward substitution to obtain the solution
<span class="math">\(x\)</span>.</li>
</ol>
</div></blockquote>
</li>
</ul>
<p>Note that switching two rows twice puts the rows back, so <span class="math">\(P\)</span> is its own
inverse. Also, note that <span class="math">\(P\)</span> is an <em>orthogonal</em> matrix, i.e., <span class="math">\(P^{-1} = P^T\)</span>,
so in general, <span class="math">\(P^{-1} = P^T = P\)</span>. The process shown above is called
<em>partial pivoting</em> because it switches rows to always get the largest diagonal
element. This is in contrast to <em>full pivoting</em> (see below) which can switch
both rows and columns to obtain the largest diagonal element. Partial pivoting
gives <span class="math">\(A=LU\)</span>, where <span class="math">\(U=M_{n-1}P_{n-1}\ldots M_1P_1A\)</span> and
<span class="math">\(L=P_1L_1\ldots P_{n-1}L_{n-1}\)</span>. Note that <span class="math">\(U\)</span> is upper triangular, but
<span class="math">\(L\)</span> is a permutation of a lower triangular matrix. It turns out that we
can write <span class="math">\(L\)</span> as <span class="math">\(L=P_1\ldots P_{n-1}L_1^P\ldots L_{n-1}^P\)</span> where
each <span class="math">\(L_k^P=I+(P_{n-1}\ldots P_{k+1}m_k)e_k^T\)</span> has the same form as
<span class="math">\(L_k\)</span>. Thus, we can write <span class="math">\(PA = L^PU\)</span> where <span class="math">\(L^P=L_1^P\ldots L_{n-1}^P\)</span>
is <em>lower triangular</em> and <span class="math">\(P=P_{n-1}\ldots P_1\)</span> is the total permutation
matrix.</p>
</div>
<div class="section" id="full-pivoting">
<h2>4.3.3. Full Pivoting<a class="headerlink" href="#full-pivoting" title="Permalink to this headline">¶</a></h2>
<p>In this case, when we are in the <span class="math">\(k^{th}\)</span> step of the Gaussian
Elimination/<span class="math">\(LU\)</span> procedure, we pick the pivot element among the <em>entire</em>
<span class="math">\((n-k+1)\times (n-k+1)\)</span> lower rightmost submatrix of <span class="math">\(A\)</span>. For
example, if <span class="math">\(k=2\)</span> and <span class="math">\(Ax=b\)</span></p>
<div class="math">
\[\begin{split}\left[
\begin{array}{cccc}
1 &amp; 2 &amp; 5 &amp; -1 \\
0 &amp; \boxed{0} &amp; 3 &amp; 1 \\
0 &amp; 4 &amp; 1 &amp; \boxed{-8} \\
0 &amp; -6 &amp; 0 &amp; 3
\end{array}
\right]\left[
\begin{array}{c}
x_1 \\
x_2 \\
x_3 \\
x_4
\end{array}
\right]=\left[
\begin{array}{c}
4 \\
7 \\
8 \\
2
\end{array}
\right]\end{split}\]</div>
<p>In this case, we can bring <span class="math">\((-8)\)</span> to the pivot position <span class="math">\(a_{22}\)</span> by
permuting <em>both</em> rows <span class="math">\(2-3\)</span> <em>and</em> columns <span class="math">\(2-4\)</span>. Naturally, we will
respectively swap rows <span class="math">\(2-3\)</span> of the right hand side <span class="math">\(b\)</span>, and rows
<span class="math">\(2-4\)</span> of the vector of unknowns <span class="math">\(x\)</span>. Thus, the equivalent system
becomes</p>
<div class="math">
\[\begin{split}\left[
\begin{array}{cccc}
1 &amp; -1 &amp; 5 &amp; 2 \\
0 &amp; -8 &amp; 1 &amp; 4 \\
0 &amp; 1 &amp; 3 &amp; 0 \\
0 &amp; 3 &amp; 0 &amp; -6
\end{array}
\right]\left[
\begin{array}{c}
x_1 \\
x_4 \\
x_3 \\
x_2
\end{array}
\right]=\left[
\begin{array}{c}
4 \\
8 \\
7 \\
2
\end{array}
\right]\end{split}\]</div>
<p>This process is encoded in the LU factorization using <em>two</em> permutation matrices
<span class="math">\(P\)</span> and <span class="math">\(Q\)</span> such that <span class="math">\(\boxed{PAQ=LU}\)</span>. The solution is then
computed via</p>
<div class="math">
\[Ax=b\Rightarrow PA\underbrace{QQ^T}_{=I}x=Pb\Rightarrow (LU)(Q^Tx)=Pb\]</div>
<ol class="arabic simple">
<li>Solve <span class="math">\(Ly = Pb\)</span> using forward substitution.</li>
<li>Solve <span class="math">\(Uz = y\)</span> using backward substitution.</li>
<li>Finally, <span class="math">\(Q^Tx = z \Rightarrow QQ^T x = Qz \Rightarrow \boxed{x=Qz}\)</span>
gives the solution.</li>
</ol>
<p>To summarize:</p>
<ul>
<li><p class="first"><em>Partial pivoting</em> permutes rows, such that the pivot element in the
<span class="math">\(k^{th}\)</span> iteration is the largest number in the <span class="math">\((n-k+1)\)</span> lower
entries of the <span class="math">\(k^{th}\)</span> column. It is written, in the context of
<span class="math">\(LU\)</span> decomposition as</p>
<div class="math">
\[PA=LU\enspace\enspace\enspace\mbox{($P =$ permutation)}\]</div>
</li>
<li><p class="first"><em>Full pivoting</em> selects the pivot element in the <span class="math">\(k^{th}\)</span> iteration as
the largest element of the <span class="math">\((n-k+1)\times (n-k+1)\)</span> lower rightmost
sub-matrix of <span class="math">\(A\)</span>. It operates by permuting rows <em>and</em> columns and leads
to an <span class="math">\(LU\)</span> decomposition of</p>
<div class="math">
\[PAQ = LU\]</div>
</li>
</ul>
<p>However, there are certain categories of matrices for which we can safely use
Gaussian elimination or <span class="math">\(LU\)</span> decomposition <em>without</em> the need for pivoting
(i.e., the pivot elements will never be problematically small).</p>
<div class="topic">
<p class="topic-title first">Definition</p>
<p>A matrix <span class="math">\(A\)</span> is called <em>diagonally dominant
by columns</em> if the magnitude of every diagonal element is larger than the sum of
the magnitudes of all other entries in the same column, i.e., for every
<span class="math">\(i=1,2,\ldots, n\)</span> we have</p>
<div class="math">
\[\begin{split}|a_{ii}|&gt;\sum_{j\neq i} |a_{ji}|\end{split}\]</div>
<p>If the diagonal element exceeds in magnitude the sum of magnitudes of all other
elements in its <em>row</em>, i.e., for every <span class="math">\(i=1,2,\ldots, n\)</span> we have</p>
<div class="math">
\[\begin{split}|a_{ii}|&gt;\sum_{j\neq i} |a_{ij}|\end{split}\]</div>
<p>then the matrix is called <em>diagonally dominant by rows</em>.</p>
</div>
<div class="topic">
<p class="topic-title first">Definition</p>
<p>A symmetric matrix <span class="math">\(A\in\mathbb R^{n\times n}\)</span> is
called <em>positive definite</em> (in short SPD for &#8220;symmetric positive definite&#8221;),
if for any <span class="math">\(x\in\mathbb R^n, x\neq 0\)</span> we have <span class="math">\(x^TAx&gt;0\)</span>. If for any <span class="math">\(x\in\mathbb R^n, x\neq 0\)</span>
we have <span class="math">\(x^TAx\geq0\)</span>, the matrix is called positive semi-definite. If the
respective properties are <span class="math">\(x^TAx&lt;0\)</span> (or <span class="math">\(x^TAx\leq 0\)</span>) the matrix is called
negative (semi) definite.</p>
</div>
<div class="topic">
<p class="topic-title first">Definition</p>
<p>The <span class="math">\(k^{th}\)</span> <em>leading principal minor</em> of a
matrix <span class="math">\(A\in\mathbb R^{n\times n}\)</span> is the determinant of the top-leftmost
<span class="math">\(k\times k\)</span> sub-matrix of <span class="math">\(A\)</span>. Thus, if we denote this minor by <span class="math">\(M_k\)</span>:</p>
<div class="math">
\[\begin{split}M_1=|a_{11}|, \enspace\enspace M_2=
\left|
\begin{array}{cc}
a_{11} &amp; a_{12} \\
a_{21} &amp; a_{22}
\end{array}
\right|,\enspace\enspace \ldots \enspace\enspace
M_k=\left|
\begin{array}{ccc}
a_{11} &amp; \ldots &amp; a_{1k} \\
\vdots &amp; &amp; \vdots \\
a_{k1} &amp; \ldots &amp; a_{kk}
\end{array}
\right|\end{split}\]</div>
</div>
<div class="topic">
<p class="topic-title first">Theorem 1</p>
<p>If <em>all</em> leading principal minors (i.e., for <span class="math">\(k=1,2,3,\ldots,n\)</span>) of the
symmetric matrix <span class="math">\(A\)</span> are positive, then <span class="math">\(A\)</span> is positive definite. If <span class="math">\(M_k&lt;0\)</span> for
<span class="math">\(k = \mbox{odd}\)</span> and <span class="math">\(M_k&gt;0\)</span> for <span class="math">\(k = \mbox{even}\)</span>, then <span class="math">\(A\)</span> is negative
definite.</p>
</div>
<div class="topic">
<p class="topic-title first">Theorem 2</p>
<p>Pivoting is <em>not</em> necessary when <span class="math">\(A\)</span> is diagonally dominant by columns, or
symmetric and positive (or negative) definite.</p>
</div>
<p>These &#8220;special&#8221; classes of matrices (which appear quite often in engineering
and applied sciences) not only make <span class="math">\(LU\)</span> decomposition more robust, but also
open some additional possibilities for solving <span class="math">\(Ax=b\)</span>.</p>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">4.3. LU Decomposition</a><ul>
<li><a class="reference internal" href="#elimination-matrices">4.3.1. Elimination Matrices</a></li>
<li><a class="reference internal" href="#existence-and-uniqueness">4.3.2. Existence and Uniqueness</a></li>
<li><a class="reference internal" href="#full-pivoting">4.3.3. Full Pivoting</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="lower.html"
                        title="previous chapter">4.2. Lower Triangular Systems</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/lu_decomp.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="lower.html" title="4.2. Lower Triangular Systems"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">CS 323 1.0 documentation</a> &raquo;</li>
          <li class="nav-item nav-item-1"><a href="linear.html" >4. Linear Systems of Equations</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &copy; Copyright 2017, Mridul Aanjaneya.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.3.6.
    </div>
  </body>
</html>